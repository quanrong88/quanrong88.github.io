<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Tạ Minh Quân,ta.quan@icloud.com"><title>Building the centralized logging system using Elasticsearch, Fluentd, Kibana · Tạ Quân</title><meta name="description" content="A problem with microservice management is how to analysis massive logs from different services and understand what is going on in system. In this arti"><meta name="keywords" content="Hexo,Swift,Refactoring,iOS,Docker"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">Tạ Quân</a></h3><div class="description"><p>Just make it simple.</p></div></div></div><ul class="social-links"><li><a href="https://twitter.com/quanrong"><i class="fa fa-twitter"></i></a></li><li><a href="http://facebook.com/churongmayman"><i class="fa fa-facebook"></i></a></li><li><a href="http://github.com/quanrong88"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/archives">Archive</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"></a></li></div><div class="avatar"><img src="/images/blog_ava.jpg"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Building the centralized logging system using Elasticsearch, Fluentd, Kibana</a></h3></div><div class="post-content"><p>A problem with microservice management is how to analysis massive logs from different services and understand what is going on in system. In this article, we will see how we can use the <strong>EFK</strong> stack (i.e Elasticsearch, Fluentd, Kibana) to aggregate log events from our microservice from <a href="https://github.com/quanrong88/microservices-demo" target="_blank" rel="noopener">previous project</a> for <strong>searching</strong>, <strong>analyzing</strong> and <strong>visualizing</strong>.</p>
<h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><p>Let’s start with a short description of new components:</p>
<ul>
<li><p><a href="https://www.elastic.co/products/elasticsearch" target="_blank" rel="noopener">Elasticsearch</a><br>Elasticsearch is a NoSQL database which is based on Lucene search engine and is built with RESTful APIs. It is a highly flexible and distributed search and analytics engine. Also, it provides simple deployment, maximum reliability, and easy management through horizontal scalability. It provides advanced queries to perform detailed analysis and stores all the data centrally for quick search of the documents.</p>
</li>
<li><p><a href="https://www.fluentd.org" target="_blank" rel="noopener">Fluentd</a><br>Fluentd is an open source data collector, which lets you unify the data collection and consumption for a better use and understanding of data. Fluentd is one of <a href="https://docs.docker.com/config/containers/logging/configure/" target="_blank" rel="noopener">supported logging drivers</a> , it’s easy to install in our current project.</p>
</li>
<li><p><a href="https://www.elastic.co/products/kibana" target="_blank" rel="noopener">Kibana</a><br>Kibana is a data visualization tool. It is used for visualizing the Elasticsearch documents and helps the developers to have an immediate insight into it. Kibana dashboard provides various interactive diagrams, geospatial data, timelines, and graphs to visualize the complex queries done using Elasticsearch. Using Kibana you can create and save custom graphs according to your specific needs.</p>
</li>
</ul>
<p>We will implement the logging feature like following diagram:</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/architect-FEK.png">
<p>Run current project by using following command</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose up</span><br></pre></td></tr></table></figure>
<h3 id="Setup-Elasticsearch"><a href="#Setup-Elasticsearch" class="headerlink" title="Setup Elasticsearch"></a>Setup Elasticsearch</h3><p>Run elasticsearch module instance by using this command</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --name search-module -d -p 33:9200 -p 34:9300 --net test-network -e &quot;discovery.type=single-node&quot; elasticsearch</span><br></pre></td></tr></table></figure>
<h3 id="Setup-Fluentd-logs-aggregation"><a href="#Setup-Fluentd-logs-aggregation" class="headerlink" title="Setup Fluentd logs aggregation"></a>Setup Fluentd logs aggregation</h3><p>Firstly, we need to create new forder for fluentd, then move to this forder</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir fluentd</span><br><span class="line">$ cd fluentd</span><br></pre></td></tr></table></figure>
<p>Create a Dockerfile and paste this content into this file<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FROM fluent/fluentd:v0.12</span><br><span class="line">RUN [&quot;gem&quot;, &quot;install&quot;, &quot;fluent-plugin-elasticsearch&quot;, &quot;--no-rdoc&quot;, &quot;--no-ri&quot;, &quot;--version&quot;, &quot;1.9.5&quot;]</span><br></pre></td></tr></table></figure></p>
<p>We will create a custom image from <em>fluent/fluentd:v0.12</em> and also install the elasticsearch plugin for fluentd image. Build the custom image by this command.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t my-fluentd .</span><br></pre></td></tr></table></figure>
<p>For running logging aggregation container we need to create a config file for fluentd. Create a file name fluentd.conf and paste following content into it</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;source&gt;</span><br><span class="line">  @type forward</span><br><span class="line">  port 24224</span><br><span class="line">  bind 0.0.0.0</span><br><span class="line">&lt;/source&gt;</span><br><span class="line"></span><br><span class="line">&lt;match *.**&gt;</span><br><span class="line">  @type copy</span><br><span class="line">  &lt;store&gt;</span><br><span class="line">    @type elasticsearch</span><br><span class="line">    host search-module</span><br><span class="line">    port 9200</span><br><span class="line">    logstash_format true</span><br><span class="line">    logstash_prefix fluentd</span><br><span class="line">    logstash_dateformat %Y%m%d</span><br><span class="line">    include_tag_key true</span><br><span class="line">    type_name access_log</span><br><span class="line">    tag_key @log_name</span><br><span class="line">    flush_interval 1s</span><br><span class="line">  &lt;/store&gt;</span><br><span class="line">  &lt;store&gt;</span><br><span class="line">    @type stdout</span><br><span class="line">  &lt;/store&gt;</span><br><span class="line">&lt;/match&gt;</span><br></pre></td></tr></table></figure>
<p>In this file, we defind source log type and setting for elasticsearch plugin</p>
<p>Run logging aggregation module and name it <em>log-module</em> by typing this command</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --name log-module -d -p 35:24224 -p 35:24224/udp --net test-network -v $(pwd):/fluentd/etc -e FLUENTD_CONF=fluentd.conf my-fluentd</span><br></pre></td></tr></table></figure>
<p>Verify the Elasticsearch and Fluentd instances has been installed correct by do this testing</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -rm --net=test-network --log-driver=fluentd --log-opt fluentd-address=localhost:35 --log-opt tag=docker.test ubuntu echo &apos;hello world&apos;</span><br></pre></td></tr></table></figure>
<p>Then, run this command you should see the “hello world” log in the return JSON</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XGET &apos;http://localhost:33/_all/_search?q=*&apos;</span><br></pre></td></tr></table></figure>
<h3 id="Setup-Kibana"><a href="#Setup-Kibana" class="headerlink" title="Setup Kibana"></a>Setup Kibana</h3><p>Run Kibana module by using this command</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --name kibana-module -d -p 36:5601 --net test-network -e ELASTICSEARCH_URL=http://search-module:9200 kibana</span><br></pre></td></tr></table></figure>
<p>Verify the Kibana installed by opening web browser and enter <a href="http://localhost:36/" target="_blank" rel="noopener">http://localhost:36/</a> , you should see the Kibana web interface. Then, you need to set up the index name pattern for Kibana. Please specify fluentd-<em> to </em>Index name or pattern<em> and press </em>Create* button</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/kibana-first-launch.png">
<p>Then, in web browser open <a href="http://localhost:30/api/#" target="_blank" rel="noopener">http://localhost:30/api/#</a> , you need to do some action with data like create/update/get some elements to database. This actions is use for generating some logs. If everything is configured correctly, you will see the this result interface when go to <em>Discover</em> tab to seek for the logs.</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/discover-tab-kibana.png">
<p>As you can see, logs are properly collected into Elasticsearch + Kibana, via Fluentd.</p>
<h3 id="Create-Kibana-visualizations"><a href="#Create-Kibana-visualizations" class="headerlink" title="Create Kibana visualizations"></a>Create Kibana visualizations</h3><h4 id="Pie-Chart"><a href="#Pie-Chart" class="headerlink" title="Pie Chart"></a>Pie Chart</h4><p>Go to <em>Visualize</em> tab, then select + icon to create our first data visualization</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/plus-icon-visualize-kibana.png">
<p>After that, you will see the the create new visualization Interface_description_language. We will create a pie chart so select <strong>pie</strong> in the interface.</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/create-visualize-ui-kibana.png">
<p>In next step <strong>Choose search resource</strong> choice fluentd-<em> from <em>*From a New Search, Select Index</em></em> list. This is the only index we have now. After that , we will see the New Visualization UI</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/new-visualize-ui-kibana.png">
<p>Under <strong>Select buckets type</strong> , select <strong>Split Slices</strong> then fill other fields like following screenshot</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/pie-chart-settings-kibana.png">
<p>In this chart, we want to see the percent of each container in the logs. Press the play button over the setting form. This is the results</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/complete-pie-chart-kibana.png">
<p>Click <strong>Save</strong> button on the top bar to save the visualization, enter the name <em>pie chart container name</em></p>
<h4 id="Bar-Chart"><a href="#Bar-Chart" class="headerlink" title="Bar Chart"></a>Bar Chart</h4><p>We want to compare the number of logs each container has sent and the number of source of the log. The bar chart is idea for this requirement. Go back to the main <em>Visualize</em> dashboard , create new data visualization by select Verticle bar chart in menu. Repeat the same select index like above pie chart.</p>
<p>Under <strong>Select buckets type</strong>, select <strong>X-Axis</strong> then fill other field like following screenshot</p>
 <img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/bar-chart-settings-kibana.png">
<p>Press play button, you should see the result like this</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/complete-bar-chart-kibana.png">
<p>In this chart, we can see the number of log for each container and there are 2 source of logs stdout and stderr.</p>
<p>Click <strong>Save</strong> button on the top bar to save the visualization, enter the name <em>bar chart container name</em></p>
<h4 id="Area-Chart"><a href="#Area-Chart" class="headerlink" title="Area Chart"></a>Area Chart</h4><p>For displaying number of events over time break down by container name, we can use area chart in this case. Go back to the main <em>Visualize</em> dashboard , create new data visualization by select Area bar chart in menu. Repeat the same select index like above bar chart.</p>
<p>Under <strong>Select buckets type</strong>, select <strong>X-Axis</strong> then fill other field like following screenshot</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/area-chart-settings-kibana.png">
<p>Press play button, you should see the result like this</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/complete-area-chart-kibana.png">
<p>Click <strong>Save</strong> button on the top bar to save the visualization, enter the name <em>Area chart container name</em></p>
<h3 id="Create-Kibana-Dashboard"><a href="#Create-Kibana-Dashboard" class="headerlink" title="Create Kibana Dashboard"></a>Create Kibana Dashboard</h3><p>For analyzing data using visualize we created in previous section, we can create a custom dashboard for this purpose. Creating new dashboard is very simple, go to the main <em>Dashboard</em> dashboard, click + icon to create new dashboard then click Add button in the menu bar to open the <em>Add Panels</em> , in <em>Visualization</em> tab select all 3 visualization we created before.</p>
<p>Click <strong>Save</strong> button on the top bar and fill the <em>Title</em> for this dashboard with <em>Test dashboard</em> then click save.</p>
<p>This is the end result</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/final-dashboard-kibana.png">
<p>With dashboard the analyze data task become very easier for normal users. UI will be update automatic with different data set.</p>
<h3 id="Containers-health-monitor-with-Metricbeat"><a href="#Containers-health-monitor-with-Metricbeat" class="headerlink" title="Containers health monitor with Metricbeat"></a>Containers health monitor with Metricbeat</h3><p>In previous sections, we’ve used Kibana for visualizing logs data in the context of technique use case. In this section, we will see how to use metric for container health monitoring.</p>
<p>Metric is event that contain a timestamp and numeric values with store the information. They are sent periodically , it is different with other events in previous sections.</p>
<p>In this article, we will use <a href="https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-overview.html" target="_blank" rel="noopener">Metricbeat</a> to collect metric information from services in the system and start shipping data to Elasticsearch. Finally, we will visualize the data has been collected by Kibana.</p>
<h4 id="Install-Metricbeat"><a href="#Install-Metricbeat" class="headerlink" title="Install Metricbeat"></a>Install Metricbeat</h4><p>First thing need to do is create configuration file for metricbeat. In the root forder of the project create new directory named metricbeat and change working directory to this directory. Type following command to prompt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir metricbeat</span><br><span class="line">$ cd metricbeat</span><br></pre></td></tr></table></figure>
<p>Create a file named <strong>metricbeat.yml</strong> and following content into this file</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">metricbeat.modules:</span><br><span class="line">- module: docker</span><br><span class="line">  metricsets: [&quot;container&quot;, &quot;cpu&quot;, &quot;diskio&quot;, &quot;healthcheck&quot;, &quot;info&quot;, &quot;memory&quot;, &quot;network&quot;]</span><br><span class="line">  hosts: [&quot;unix:///var/run/docker.sock&quot;]</span><br><span class="line">  period: 10s</span><br><span class="line">fields:</span><br><span class="line">  env: dev</span><br><span class="line"></span><br><span class="line">output.elasticsearch:</span><br><span class="line">  hosts: [&quot;search-module:9200&quot;]</span><br></pre></td></tr></table></figure>
<p>In this file, we define using the Docker module, Metricbeat can be configured to ship a bunch of useful information about Docker containers running on the host. We also define the output for Metricbeat to elasticsearch using address <em>search-module:9200</em></p>
<p>Run the Metricbeat module by using this command</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d -it --name beat-module --net test-network -u root --mount type=bind,source=&quot;$(pwd)&quot;/metricbeat.yml,target=/usr/share/metricbeat/metricbeat.yml -v /var/run/docker.sock:/var/run/docker.sock  docker.elastic.co/beats/metricbeat:6.4.2</span><br></pre></td></tr></table></figure>
<p>Next, open web browser and open Kibana page by type address <em>localhost:36</em>, select <strong>Management</strong> dashboard then select <strong>Index Patterns</strong>. In the <strong>Index Patterns</strong> UI, click <strong>Create Index Pattern</strong> button on the top of left Bar</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/create-index-pattern-kibana.png">
<p>In the <strong>Configure an index pattern</strong> screen , fill the form like this screenshot to create pattern for metricbeat in kibana</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/metricbeat-pattern-kibana.png">
<p>Go back to <strong>Discover</strong> and select metricbeat-* in index pattern dropdown, you should see the result like this screenshot</p>

<p>At this point , we see the data collected by metricbeat but it’s quite hard to visualize it. In next section, we will solve it.</p>
<h4 id="Set-up-the-Kibana-Dashboard"><a href="#Set-up-the-Kibana-Dashboard" class="headerlink" title="Set up the Kibana Dashboard"></a>Set up the Kibana Dashboard</h4><p>Metricbeat comes packaged with example Kibana dashboards, visualizations, and searches for visualizing Metricbeat data in Kibana. To do this, you need to provide the Kibana address for Metricbeat. Connect to <em>beat-module</em> by following command</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker exec -it beat-module bash</span><br></pre></td></tr></table></figure>
<p>In the <em>beat-module</em> command prompt enter this command to set up Kibana address</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># ./metricbeat setup -E setup.kibana.host=kibana-module:5601</span><br></pre></td></tr></table></figure>
<p>After finish installing, we can verify it by go to the Kibana page and select <strong>Visualize</strong> tab on menu bar. You should see the pre-build visualization from Metric beat has been installed</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/metricbeat-visualize-kibana.png">
<p>Open <strong>Dashboard</strong> tab, you should see the pre-build dashboard too</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/metricbeat-dashboard-kibana.png">
<p>Because in this example, we use metricbeat with docker module so we can use Metricbeat docker dashboard in above list to visualize the metrics. Select Metricbeat Docker, you should see the result like this screenshot</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/metricbeat-docker-dashboard-kibana.png">
<p>We can see how system operate over time by this dashboard. The important information about system like CPU usage, memory usage, network IO has been visualized and update automatically, Users don’t need any technique skill to understand how system currently works.</p>
<h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>In this article, we’ve built a centralized logging system for debugging and monitoring for <a href="https://github.com/quanrong88/microservices-demo/tree/master" target="_blank" rel="noopener">project</a> we done in previous article. We’ve reviewed 2 technology stacks EFK(Elasticsearch, Fluentd, Kibana) and MEK (Metricbeat, Elasticsearch, Kibana) for this requirement.</p>
<p>Here is the <a href="https://github.com/quanrong88/microservices-demo/tree/log-driven" target="_blank" rel="noopener">final project</a> of this part.</p>
<p><strong>NOTE</strong> : To run project smoothly on your local device. You have to set memory for docker in <strong>Preferences</strong> to over 4GB</p>
<img src="/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/note-docker-machine.png">
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-10-05</span><i class="fa fa-tag"></i><a href="/tags/Devops/" title="Devops" class="tag">Devops </a><a href="/tags/Visualization/" title="Visualization" class="tag">Visualization </a><a href="/tags/Logs/" title="Logs" class="tag">Logs </a><a href="/tags/Elasticsearch/" title="Elasticsearch" class="tag">Elasticsearch </a><a href="/tags/Fluentd/" title="Fluentd" class="tag">Fluentd </a><a href="/tags/Kibana/" title="Kibana" class="tag">Kibana </a><a href="/tags/Metricbeat/" title="Metricbeat" class="tag">Metricbeat </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://quanrong88.github.io/2018/10/05/Building-the-centralized-logging-system-using-Elasticsearch-Fluentd-Kibana/,Tạ Quân,Building the centralized logging system using Elasticsearch, Fluentd, Kibana,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a role="navigation" href="/2018/03/13/Building-microservice-with-GRPC-and-python/" title="Building microservice with gRPC and python" class="btn">next post</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>